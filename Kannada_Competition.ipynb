{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom keras.utils.np_utils import to_categorical\nfrom keras import models\nfrom keras import layers\n\ntrain = pd.read_csv('../input/Kannada-MNIST/train.csv')\ntest = pd.read_csv('../input/Kannada-MNIST/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"y_train = train[\"label\"]\n#remove label column from X_train\nx_train = train.drop(labels = [\"label\"],axis = 1)\nx_train = x_train.to_numpy().reshape(-1,28,28,1)\ny_train = to_categorical(y_train, num_classes = 10)\n\n# remove id column from test data\nx_test = test.copy()\nx_test.drop(labels=['id'], axis=1, inplace=True)\nx_test = x_test.to_numpy().reshape(-1,28,28,1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(x_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#rescale values to range [0, 1]\nx_train = x_train / 255.0\nx_test = x_test / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# x_additional = pd.read_csv('../input/Kannada-MNIST/Dig-MNIST.csv')\n# # prepare the additional data set\n# y_additional = x_additional['label']\n# x_additional.drop(labels=['label'], axis=1, inplace=True)\n# x_additional = x_additional.to_numpy().reshape(-1, 28, 28, 1)\n# y_additional = to_categorical(y_additional, num_classes = 10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# #prepare additional data\n# x_additional = x_additional / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #concatenate training data and additional data\n# x_train = np.concatenate((x_train, x_additional), axis=0)\n# y_train = np.concatenate((y_train, y_additional), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1, \n#     shear_range=0.1, \n    zoom_range=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"model_list = []\n\nmodel_1 = models.Sequential()\nmodel_1.add(layers.Conv2D(10, (5, 5), input_shape = (28, 28, 1)))\nmodel_1.add(layers.BatchNormalization())\nmodel_1.add(layers.Activation('relu'))\nmodel_1.add(layers.MaxPooling2D((2, 2)))\nmodel_1.add(layers.Conv2D(20, (5, 5)))\nmodel_1.add(layers.BatchNormalization())\nmodel_1.add(layers.Activation('relu'))\nmodel_1.add(layers.MaxPooling2D((2, 2)))\nmodel_1.add(layers.Flatten())\nmodel_1.add(layers.Dropout(0.5))\nmodel_1.add(layers.Dense(100))\nmodel_1.add(layers.BatchNormalization())\nmodel_1.add(layers.Activation('relu'))\nmodel_1.add(layers.Dense(10, activation = 'softmax'))\nmodel_list.append(model_1)\n\n\nmodel_2 = models.Sequential()\nmodel_2.add(layers.Conv2D(20, (3, 3), input_shape = (28, 28, 1)))\nmodel_2.add(layers.BatchNormalization())\nmodel_2.add(layers.Activation('relu'))\nmodel_2.add(layers.MaxPooling2D((2, 2)))\nmodel_2.add(layers.Conv2D(30, (5, 5)))\nmodel_2.add(layers.BatchNormalization())\nmodel_2.add(layers.Activation('relu'))\nmodel_2.add(layers.MaxPooling2D((2, 2)))\nmodel_2.add(layers.Flatten())\nmodel_2.add(layers.Dropout(0.5))\nmodel_2.add(layers.Dense(100))\nmodel_2.add(layers.BatchNormalization())\nmodel_2.add(layers.Activation('relu'))\nmodel_2.add(layers.Dense(10, activation = 'softmax'))\nmodel_list.append(model_2)\n\nmodel_3 = models.Sequential()\nmodel_3.add(layers.Conv2D(10, (3, 3), input_shape = (28, 28, 1)))\nmodel_3.add(layers.BatchNormalization())\nmodel_3.add(layers.Activation('relu'))\nmodel_3.add(layers.MaxPooling2D((2, 2)))\nmodel_3.add(layers.Conv2D(20, (5, 5)))\nmodel_3.add(layers.BatchNormalization())\nmodel_3.add(layers.Activation('relu'))\nmodel_3.add(layers.MaxPooling2D((2, 2)))\nmodel_3.add(layers.Flatten())\nmodel_3.add(layers.Dense(100))\nmodel_3.add(layers.BatchNormalization())\nmodel_3.add(layers.Activation('relu'))\nmodel_3.add(layers.Dense(10, activation = 'softmax'))\nmodel_list.append(model_3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import keras\ncallbacks_lists = []\nfor i in range(3):\n    callbacks_list = [\n        keras.callbacks.EarlyStopping(\n            monitor='val_accuracy',\n            patience=2,\n        ), \n        keras.callbacks.ModelCheckpoint(\n                filepath='ensemble_model_' + str(i) + '.h5',\n                monitor='val_accuracy',\n                save_best_only=True,\n        )\n    ]\n    callbacks_lists.append(callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras import optimizers\n\nfor i in range(3):\n    model_list[i].compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfor i in range(3):\n    #split data into training set and validation set\n    x_train_2, x_val_2, y_train_2, y_val_2 = train_test_split(x_train, y_train, test_size = 0.2)\n    epoch_step = x_train.shape[0]/64\n    history = model_list[i].fit_generator(train_datagen.flow(x_train_2, y_train_2, batch_size=64), \n                              epochs = 50, callbacks = callbacks_lists[i], \n                              steps_per_epoch = epoch_step, validation_data = (x_val_2,y_val_2))\n    print('history: ', history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from keras.models import load_model\nfrom sklearn.metrics import accuracy_score\n\nresults = np.zeros((x_test.shape[0], 10))\n# results_additional = np.zeros((x_additional.shape[0], 10))\nfor i in range (3):\n    saved_model = load_model('ensemble_model_' + str(i) + '.h5')\n    result = saved_model.predict(x_test)\n    results += result\n#     result_additional = saved_model.predict(x_additional)\n#     results_additional += result_additional\n    \nbest_result = np.argmax(results,axis = 1)\n# best_result_additional = np.argmax(results_additional,axis = 1)\n\n# best_additional_accuracy = accuracy_score(y_additional, best_result_additional)\n# print('best_additional_accuracy', best_additional_accuracy)\n\nfinal_result = pd.Series(best_result,name=\"label\")\nsubmission = pd.concat([pd.Series(range(0,x_test.shape[0]),name = \"id\"),final_result],axis = 1)\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}